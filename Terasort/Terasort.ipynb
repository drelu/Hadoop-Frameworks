{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terasort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HADOOP_EXAMPLES=\"/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/hadoop-mapreduce-examples.jar\"\n",
    "HADOOP_STREAMING=\"/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/hadoop-streaming.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/11/19 20:57:40 INFO impl.TimelineClientImpl: Timeline service address: http://radical-2:8188/ws/v1/timeline/\n",
      "15/11/19 20:57:41 INFO client.RMProxy: Connecting to ResourceManager at radical-2/10.20.109.61:8050\n",
      "15/11/19 20:57:41 INFO terasort.TeraSort: Generating 1000000000 using 2\n",
      "15/11/19 20:57:41 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "15/11/19 20:57:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1447817101091_0010\n",
      "15/11/19 20:57:41 INFO impl.YarnClientImpl: Submitted application application_1447817101091_0010\n",
      "15/11/19 20:57:41 INFO mapreduce.Job: The url to track the job: http://radical-2:8088/proxy/application_1447817101091_0010/\n",
      "15/11/19 20:57:41 INFO mapreduce.Job: Running job: job_1447817101091_0010\n"
     ]
    }
   ],
   "source": [
    "!yarn jar $HADOOP_EXAMPLES teragen 1000000000 teragen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -mv teragen teragen-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "drwx------   - luckow hdfs          0 2015-11-19 21:37 .staging\r\n",
      "drwxr-xr-x   - luckow hdfs          0 2015-11-19 21:37 teragen-100\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLINK_HOME=\"/usr/hdp/2.3.2.0-2950/flink-0.10.0/\"\n",
    "HADOOP_CONF_DIR=\"/etc/hadoop/conf\"\n",
    "NUM_TASKS=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/hdp/2.3.2.0-2950/flink-0.10.0/\r\n"
     ]
    }
   ],
   "source": [
    "!echo {FLINK_HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing argument for option: p\r\n",
      "\r\n",
      "Use the help option (-h or --help) to get help on the command.\r\n"
     ]
    }
   ],
   "source": [
    "!/usr/hdp/2.3.2.0-2950/flink-0.10.0/bin/flink run -m yarn-cluster -yn 32 -ys 8 -p $NUM_TASKS -ytm 92000 -c org.apache.flink.test.recordJobs.sort.TeraSort $FLINK_SRC/flink-tests/target/flink-tests-0.9-SNAPSHOT-tests.jar $NUM_TASKS hdfs:///user/luckow/hadoop-terasort/ hdfs:///user/luckow/flink-teraout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!{FLINK_HOME}/bin/yarn-session.sh -n 4 -jm 92000 -s 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!echo $YARN_CONF_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:52:02,872 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "22:52:02,929 WARN  org.apache.hadoop.util.NativeCodeLoader                       - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22:52:03,078 WARN  org.apache.flink.yarn.FlinkYarnClient                         - Neither the HADOOP_CONF_DIR nor the YARN_CONF_DIR environment variable is set.The Flink YARN Client needs one of these to be set to properly load the Hadoop configuration for accessing YARN.\n",
      "22:52:03,078 INFO  org.apache.flink.yarn.FlinkYarnClient                         - Using values:\n",
      "22:52:03,079 INFO  org.apache.flink.yarn.FlinkYarnClient                         - \tTaskManager count = 4\n",
      "22:52:03,079 INFO  org.apache.flink.yarn.FlinkYarnClient                         - \tJobManager memory = 92000\n",
      "22:52:03,079 INFO  org.apache.flink.yarn.FlinkYarnClient                         - \tTaskManager memory = 1024\n",
      "22:52:04,135 INFO  org.apache.hadoop.ipc.Client                                  - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n",
      "22:52:05,135 INFO  org.apache.hadoop.ipc.Client                                  - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n",
      "22:52:06,136 INFO  org.apache.hadoop.ipc.Client                                  - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n",
      "22:52:07,137 INFO  org.apache.hadoop.ipc.Client                                  - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n",
      "22:52:08,137 INFO  org.apache.hadoop.ipc.Client                                  - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n",
      "22:52:09,138 INFO  org.apache.hadoop.ipc.Client                                  - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n",
      "22:52:10,138 INFO  org.apache.hadoop.ipc.Client                                  - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!/usr/hdp/2.3.2.0-2950/flink-0.10.0/bin/yarn-session.sh -n 4 -jm 92000 -s 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
